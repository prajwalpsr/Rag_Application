# ğŸš€ Simple RAG Application  
### **Qdrant + LlamaIndex + Ollama + FastAPI + Inngest + Streamlit**

A fully open-source Retrieval-Augmented Generation (RAG) application built using:

- **Qdrant** â€“ Vector Database  
- **LlamaIndex** â€“ Chunking, Embeddings & RAG Engine  
- **Ollama** â€“ Local LLM Inference (Llama3 or any open model)  
- **FastAPI** â€“ Backend API  
- **Inngest** â€“ Background workflows for ingestion  
- **Streamlit** â€“ Frontend UI  
- **uv** â€“ Fast Python environment manager and dependency installer

This project demonstrates how to build a clean, local-first RAG pipeline that requires **no paid APIs** and can run completely offline.

---

# ğŸ“¦ Features

- ğŸ“„ PDF / TXT / MD document ingestion  
- ğŸ” Vector search using Qdrant  
- ğŸ¤– Local LLM inference powered by Ollama  
- âš¡ LlamaIndex RAG pipeline (chunking â†’ embedding â†’ retrieval â†’ synthesis)  
- ğŸ” Inngest background workflows  
- ğŸ–¥ï¸ Streamlit UI for user interaction  
- ğŸ”Œ FastAPI backend with clean endpoints  
- ğŸ—„ï¸ Persistent vector storage  
- ğŸ’¡ Works entirely offline  

---

# ğŸ› ï¸ Tech Stack

| Component      | Purpose |
|----------------|---------|
| **Qdrant**     | Vector DB to store embeddings |
| **LlamaIndex** | Chunking, embedding, retrieval |
| **Ollama**     | Local LLM inference |
| **FastAPI**    | Backend server |
| **Inngest**    | Async workflows (ingestion jobs) |
| **Streamlit**  | User interface |
| **uv**         | Python env + dependency manager |

---

# ğŸ”§ Installation (New System Setup)

Follow these steps on any new machine before running the app.

## **1ï¸âƒ£ Install Python**
https://www.python.org/downloads/

---

## **2ï¸âƒ£ Install uv**
```bash
pip install uv
